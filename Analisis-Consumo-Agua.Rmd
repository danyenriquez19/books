--- 
    title: "PREDICCIÓN DEL CONSUMO DE AGUA UTILIZANDO SERIES DE TIEMPO GENERADAS POR MEDIDORES INTELIGENTES"
    author: "Dany Enriquez"
    date: "`r Sys.Date()`"
    site: bookdown::bookdown_site
    output: bookdown::gitbook
    documentclass: book
    bibliography: [book.bib, packages.bib]
    biblio-style: apalike
    link-citations: yes
    github-repo: rstudio/bookdown-demo
    language:
      ui:
        chapter_name: "Capítulo "
        appendix_name: "Apéndice "
        toc: "Tabla de contenido"
        references: "Referencias"
        search: "Buscar"
      label:
        fig: "Figura "
        tab: "Tabla "
        eq: "Ecuación "
        thm: "Teorema "
        lem: "Lema "
        cor: "Corolario "
        prp: "Proposición "
        cnj: "Conjetura "
        def: "Definición "
        exm: "Ejemplo "
        exr: "Ejercicio "
        proof: "Demostración"

---


# Importancia del Análisis del Consumo de Agua

El uso responsable del agua representa uno de los principales desafíos de la sociedad contemporánea, debido a factores como el cambio climático, la contaminación y la sobreexplotación de los recursos hídricos. Estas problemáticas comprometen seriamente la sostenibilidad de la vida urbana y el equilibrio de los ecosistemas.

Frente a este escenario, diversas ciudades han comenzado a implementar soluciones tecnológicas, como los medidores inteligentes, que permiten monitorear y controlar el consumo de agua por parte de la población. Estos dispositivos generan datos detallados a lo largo del tiempo, lo que facilita la detección de patrones de uso, así como la identificación de comportamientos anómalos o indicios de fraude. Esta información resulta fundamental para diseñar estrategias que promuevan un uso más eficiente y responsable del recurso hídrico.

Existen numerosos estudios que abordan esta problemática desde diferentes enfoques. En el presente trabajo se tomará como referencia un conjunto de datos recopilado en el marco del proyecto europeo DAIAD, financiado por el Séptimo Programa Marco de la Unión Europea [@daiad_project]. Este conjunto contiene series temporales de consumo de agua registradas por medidores inteligentes (Smart Water Meters, SWM) instalados en 1007 hogares de la ciudad de Alicante, gestionados por la empresa AMAEM.

El objetivo de este estudio es generar pronósticos de consumo a partir de dicha información, con el fin de comprender los patrones de comportamiento en el uso del agua y, en consecuencia, poner estos resultados a disposición de las entidades o actores interesados, para apoyar la toma de decisiones y fomentar un uso más eficiente y sostenible del recurso.

Los datos utilizados en este análisis provienen del conjunto titulado Smart Water Meter Consumption Time Series[@smart_water_meters], el cual está disponible públicamente en el portal de la Hellenic Data Service y se encuentra licenciado bajo los términos de CC BY-SA 4.0. Este recurso proporciona una base sólida para el desarrollo de modelos de pronóstico y análisis de patrones de consumo de agua.

<!--chapter:end:index.Rmd-->

# Analisis Exploratorio de Datos

## Selección de Usuario

Ya que en la base de datos existen múltiples series de tiempo asociadas a cada usuario en el registro. Para simplificar el análisis y los temas tratados en este trabajo, se seleccionará un usuario de manera aleatoria. Este usuario servirá como base para desarrollar los análisis y conclusiones que se presentarán en las siguientes secciones.

El usuario selccionado al azar tiene user.key 4f7729cf-f0fc-4333-bea7-4ee4aeaaa246

```{r, echo=FALSE}

df<-read.csv2("usuario_aleatorio.csv")
```



```{r diccionario-tabla, echo=FALSE, warning=FALSE}
library(knitr)

kable(
  data.frame(
    Variable = c("user.key", "datetime", "meter.reading", "diff"),
    Descripción = c(
      "Llave de usuario que permite identificar al usuario.",
      "Fecha y hora en que el medidor realizó la lectura.",
      "Lectura acumulada del consumo en metros cúbicos.",
      "Diferencia de consumo respecto a la medición anterior."
    )
  ),
  caption = "Diccionario de variables de la serie de consumo."
)
```
## Rango de las Mediciones


primeros 5 registros.

```{r, echo=FALSE}
head(df, 5)
```

últimos 5 registros

```{r, echo=FALSE}
tail(df, 5)
```

El análisis de los datos revela que los registros fueron tomados en intervalos de una hora. El período de recopilación abarca desde el año 2015 hasta 2017 y ya se han calculado la diferencia en los consumos.

## Valores Faltantes

```{r, echo=FALSE}

nulos<-sum(is.na(df))
cat("la base de datos cuenta con ",nulos,"valores faltantes" )

```

## Formato de las variables

```{r, echo=FALSE}
sapply(df, class)
```

podemos observar que la variable "datetime" no esta en formato de fecha.

```{r, echo=FALSE}

df$datetime <- as.POSIXct(df$datetime, format = "%d/%m/%Y %H:%M:%S")


# Convertir a formato de fecha y hora
df$datetime <- as.POSIXct(df$datetime, format = "%d/%m/%Y %H:%M:%S")


```


## Estadisticas Descriptivas

Para nuestro análisis descriptivo tendremos en cuenta la variable 'diff' ya que representa el consumo realizado en determinada hora por el medidor.

```{r, echo=FALSE, warning=FALSE}
media<-mean(df$diff)
mediana<-median(df$diff)
deves<- sd(df$diff)
minimo<-min(df$diff)
maximo<-max(df$diff)
rango<- maximo-minimo
cv<-(deves/media)*100
Q1<-quantile(df$diff,0.25)
Q2<-quantile(df$diff,0.5)
Q3<-quantile(df$diff,0.75)

kable(
  data.frame(
    Variable = c("media", "mediana", "desv. estandar", "Minimo","Maximo","Rango", "Coef. Variacion", "Q1","Q2","Q3"),
    Descripción = c(
      media, mediana,deves,minimo,maximo,rango,cv,Q1,Q2,Q3
    )
  ),
  caption = "Estadisticas Descriptivas de la variable diff para el usuario seleccionado."
)
```

<<<<<<< HEAD
El análisis revela valores de consumo anormalmente elevados en determinadas horas, lo que evidencia la presencia de valores atípicos y una considerable variabilidad en la serie temporal, ademas de valores con consumos negativos
=======
El análisis revela valores de consumo anormalmente elevados en determinadas horas, lo que evidencia la presencia de valores atípicos y una considerable variabilidad en la serie temporal, ademas de valores negativos los cuales se imputaran.

## Valores Negativos

```{r, echo=FALSE}
# Contar valores negativos en diff
num_negativos <- sum(df$diff < 0, na.rm = TRUE)

# Mostrar cuántos negativos hay
cat("Número de valores negativos en diff:", num_negativos, "\n")

```

## Imputar Valores Negativos

```{r, echo=FALSE}
# Imputar (reemplazar) valores negativos por cero
df <- df %>%
  mutate(diff = ifelse(diff < 0, 0, diff))

# Confirmar que ya no hay valores negativos
num_negativos_despues <- sum(df$diff < 0, na.rm = TRUE)
cat("Número de valores negativos después de imputar:", num_negativos_despues, "\n")
```
>>>>>>> b759291 (Renderizado actualizado del libro)



Se adicionara el consumo por año

```{r, echo=FALSE, warning=FALSE,message=FALSE}
library(dplyr)
library(knitr)
library(kableExtra)
library(lubridate)
library(kableExtra)
library(dplyr)
tabla_resumen <- df %>%
  mutate(anio = format(datetime, "%Y")) %>%
  filter(anio %in% c("2015", "2016", "2017")) %>%
  group_by(anio) %>%
  summarise(
    promedio_consumo = mean(diff, na.rm = TRUE),
    varianza_consumo = var(diff, na.rm = TRUE)
  )

tabla_resumen %>%
  kable(digits = 2, caption = "Promedio y Varianza del Consumo por Año") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

## valores Negativos 

```{r}
valores_negativos <- df %>% filter(diff < 0)
valores_negativos
```

## Imputacion Valores negativos

```{r,echo=FALSE}
library(magrittr)
library(dplyr)

# Ejemplo simple de df con diff
df <- data.frame(diff = c(-3, 0, 5, -1, 7))

# Reemplazar valores negativos en diff por 0
df <- df %>%
  mutate(diff = ifelse(diff < 0, 0, diff))

# Contar valores negativos después (debería ser 0)
num_negativos_despues <- sum(df$diff < 0, na.rm = TRUE)
cat("Número de valores negativos después de imputar:", num_negativos_despues, "\n")

```


## Resumen Analisis Estadistico

Se observa que el consumo de agua presenta una notable variabilidad y numerosos valores atípicos. El rango de consumo oscila entre 0 y 2152 metros cúbicos por hora. Sin embargo, el valor promedio general se encuentra alrededor de los 33 metros cúbicos, lo cual sugiere que, aunque existen registros extremos de consumo, la mayoría de los valores se concentran en niveles mucho más bajos. Esta disparidad podría indicar posibles irregularidades en los datos o un comportamiento inconsistente en el consumo de agua.

## Analisis Grafico

En este apartado analizaremos los diferentes comportamientos de la variable "diff" en el tiempo, haciendo uso de gráfico.

**Boxplot**


```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(lubridate)

ggplot(df,aes(x="", y= diff))+geom_boxplot(fill="darkblue", color = "lightblue")+ labs(x="", y= "consumo(diff)")+ theme_minimal()


```

**Consumo Anual**

```{r boxplot-diff-anio, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)

# Asegúrate de que df esté definido previamente
df <- df %>%
  mutate(anio = lubridate::year(datetime))  # usa lubridate::year si datetime es POSIXct

ggplot(df, aes(x = as.factor(anio), y = diff)) +
  geom_boxplot(fill = "lightgreen", color = "darkgreen") +
  labs(x = "Año", y = "Consumo (diff)") +
  theme_minimal()
```

se observa una gran presencia de registros atipicos por cada uno de los años registrados.


```{r, echo=FALSE, warning=FALSE,message=FALSE}
library(kableExtra)
library(dplyr)
library(knitr)

# Calcular los valores atípicos por año usando dplyr:: prefijos
outliers_por_anio <- df %>%
  group_by(anio) %>%
  dplyr::mutate(
    Q1 = quantile(diff, 0.25, na.rm = TRUE),
    Q3 = quantile(diff, 0.75, na.rm = TRUE),
    IQR = Q3 - Q1,
    es_outlier = diff < (Q1 - 1.5 * IQR) | diff > (Q3 + 1.5 * IQR)
  ) %>%
  dplyr::summarise(
    total = n(),
    outliers = sum(es_outlier, na.rm = TRUE),
    porcentaje = round(100 * outliers / total, 2),
    .groups = "drop"
  )

#Mostrar tabla con kable
kable(outliers_por_anio,
      caption = "Valores Atípicos por Año", 
      format = "markdown")

```




## Serie de Tiempo

**Consumo General**

```{r,echo=FALSE,warning=FALSE,message=FALSE}
#install.packages("zoo")
#install.packages("plotly")
library(zoo)
library(plotly)


plot_ly(
  data = df,
  x = ~datetime,
  y = ~diff,
  type = 'scatter',
  mode = 'lines',
  line = list(color = 'steelblue')
) %>%
  layout(
    title = "Serie de Tiempo del Consumo de Agua",
    xaxis = list(title = "Fecha"),
    yaxis = list(title = "Consumo de Agua (m3/h)")
  )
           

```

**Consumo anual**




```{r,echo=FALSE}
library(plotly)
library(dplyr)

df$year <- format(df$datetime, "%Y")
df$month <- format(df$datetime, "%m")

# Generar los gráficos por año
plots_por_ano <- df %>%
  group_by(year) %>%
  group_split() %>%
  lapply(function(sub_df) {
    plot_ly(sub_df, x = ~datetime, y = ~diff, type = 'scatter', mode = 'lines',
            name = unique(sub_df$year))
  })

# Crear el subplot
fig <- subplot(plots_por_ano, nrows = length(plots_por_ano),
               shareX = FALSE, shareY = TRUE, titleY = TRUE)

# Agregar el layout general
fig <- fig %>%
  layout(
    title = list(text = "Consumo de Agua por Año (Mes a Mes)", x = 0.5),
    xaxis = list(title = "Fecha"),
    yaxis = list(title = "Consumo de Agua (m³/h)"),
    annotations = list(
      list(
        text = "Consumo de Agua por Año (Mes a Mes)",
        x = 0.5,
        y = 1.05,
        xref = "paper",
        yref = "paper",
        showarrow = FALSE,
        font = list(size = 16)
      )
    )
  )

fig


```

## Resultados Analisis Grafico

* Se observa la presencia de consumos elevados, lo cual se ve reflejado en la existencia de múltiples valores atípicos que sobresalen del comportamiento general de la serie.

* La serie presenta picos de consumo significativamente altos, evidenciando una variabilidad considerable y la presencia de numerosos valores atípicos que podrían estar asociados a eventos específicos o errores de medición.

* A través de los años se observa que los consumos por mes van disminuyendo.

## Medias Moviles 

Dado que los registros de consumo de agua se han tomado en intervalos de una hora, se ha decidido utilizar un parámetro de k=24 para las medias móviles, lo que corresponde a un promedio de 24 horas, es decir, un promedio diario. Esta elección permite suavizar las fluctuaciones horarias y capturar las tendencias generales del consumo de agua a lo largo de cada día. De este modo, se obtiene una representación más clara y coherente del comportamiento del consumo en el tiempo, eliminando los efectos de variaciones momentáneas que podrían ser causadas por fluctuaciones o eventos aislados

```{r,echo=FALSE}
df$movil_24 <- zoo::rollmean(df$diff, k = 24, fill = NA, align = "right")
plot_ly(df, x = ~datetime) %>%
  add_lines(y = ~diff, name = "Serie Original", line = list(color = 'gray')) %>%
  add_lines(y = ~movil_24, name = "Media Móvil (24 horas)", line = list(color = 'blue')) %>%
  layout(
    title = "Consumo de Agua y Media Móvil (24 horas)",
    xaxis = list(title = "Fecha"),
    yaxis = list(title = "Consumo de Agua (m3/h)"),
    legend = list(x = 0.1, y = 0.9)
  )

```

A partir del gráfico de medias móviles (calculadas como promedios diarios utilizando un intervalo de 24 horas), se observa que el comportamiento general de la serie de consumo se mantiene relativamente estable a lo largo del tiempo. Sin embargo, se identifican dos fechas con variaciones atípicas significativas: el 21 de abril de 2015 y el 30 de diciembre de 2016, en las cuales se registran picos inusuales en el consumo.

## Rezagos

```{r,echo=FALSE,warning=FALSE,message=FALSE}
df <- df %>%
  mutate(lag_1 = lag(diff, 1))
ggplot(df, aes(x = lag_1, y = diff)) +
  geom_point() +
  labs(title = "Relación entre el consumo actual y el rezago de 1",
       x = "Consumo de Agua - Rezago 1",
       y = "Consumo de Agua Actual") +
  theme_minimal()

```


Se observa una clara concentración de puntos en los valores bajos de consumo, lo que indica que la mayoría de las observaciones corresponden a registros con bajo consumo horario. Además, la relación entre el consumo actual y su rezago de una hora no presenta un patrón lineal evidente. Esta falta de linealidad sugiere que no es posible realizar predicciones precisas basadas únicamente en el valor rezagado.

## Estacionalidad

Dado que los registros de los medidores se realizaron de forma horaria desde el 1 de enero de 2015 hasta el 19 de mayo de 2017, es necesario definir adecuadamente el periodo sobre el cual se analizará la estacionalidad, con el fin de identificar posibles patrones recurrentes. No se optó por un análisis mensual, ya que el último mes de la serie no está completo. Además, dado el alto nivel de detalle de los datos (una observación por hora), trabajar a nivel diario u horario podría dificultar la visualización de patrones estacionales debido a la gran cantidad de observaciones. Por esta razón, se decidió realizar el análisis de estacionalidad a nivel semanal.


```{r,echo=FALSE, warning=FALSE,message=FALSE}
#install.packages("forecast")
library(dplyr)
library(lubridate)
library(forecast)

# Recorta hasta el último domingo completo antes del 19 de mayo de 2017
fecha_max <- as.Date("2017-05-19")
fecha_fin <- fecha_max - wday(fecha_max) + 1  
df_truncado <- df %>% 
  filter(as.Date(datetime) <= fecha_fin)
# truncar la serie
df_semanal <- df_truncado %>%
  mutate(semana = floor_date(datetime, "week")) %>%
  group_by(semana) %>%
  summarise(consumo_semanal = sum(diff, na.rm = TRUE)) %>%
  ungroup()
# crear la serie
serie_semanal <- ts(df_semanal$consumo_semanal, 
                    start = c(2015, 1), 
                    frequency = 52)
# graficar la serie
ggseasonplot(serie_semanal,
             year.labels = TRUE, 
             year.labels.left = TRUE,
             col = rainbow(10),
             main = "Estacionalidad Semanal por Año",
             ylab = "Consumo (m3/h)", 
             xlab = "Semana")
```

El gráfico de estacionalidad muestra el comportamiento mensual del consumo de agua para los años 2015, 2016 y 2017. Se observa una cierta regularidad en los años 2015 y 2016, lo que indica un patrón estacional moderado. Sin embargo, en 2017 se detecta una fuerte caída en el mes de mayo, lo que rompe el patrón observado en años anteriores y sugiere una posible anomalía o cambio en la dinámica del consumo.

## Autocorrelaciones

Se realizará un análisis de autocorrelación y autocorrelación parcial con el objetivo de evaluar si los valores pasados influyen significativamente en los valores futuros de la serie. Este análisis permitirá identificar la presencia de dependencias temporales que puedan ser útiles para la modelación y predicción del comportamiento del consumo.

```{r}

acf(serie_semanal, main = "Autocorrelación del Consumo Semanal")

pacf(serie_semanal, main = "Autocorrelación Parcial del Consumo Semanal")

```

Se realizó el análisis de autocorrelación (ACF) del consumo semanal para evaluar la dependencia temporal entre observaciones. Los resultados muestran una fuerte autocorrelación positiva en los primeros lags, lo que indica que los valores de consumo de una semana están significativamente influenciados por los valores de semanas anteriores. La autocorrelación disminuye de manera progresiva, pero se mantiene significativa hasta aproximadamente 15 semanas, lo que sugiere una estructura persistente en el consumo a lo largo del tiempo.


# Prepocesamiento de Datos

## Descomposicion de la Serie

Dada la variabilidad en los niveles de la serie y la presencia de una estacionalidad cuya amplitud cambia en función del tiempo, se optó por aplicar una descomposición multiplicativa. Para ello, se realizó una transformación logarítmica previa sobre la serie, lo que permite utilizar un enfoque aditivo con el método stl(), manteniendo así la naturaleza multiplicativa de los componentes al interpretar los resultados en la escala original.

**verificacion de ceros en la serie**

```{r, echo=FALSE}
# Ver cuántos ceros hay
sum(serie_semanal == 0, na.rm = TRUE)

# Ver cuántos valores negativos hay
sum(serie_semanal < 0, na.rm = TRUE)

```


  
```{r, echo=FALSE}
# serie por semana
serie_log<-log(serie_semanal)
descomposicion <- stl(serie_log,s.window = "periodic")
plot(descomposicion)
```

Se observa una estacionalidad bien definida en la serie, lo que indica patrones recurrentes a lo largo del tiempo. En cuanto a la tendencia, se aprecia una disminución progresiva del consumo semanal hasta aproximadamente mediados del año 2016, momento en el que la serie parece estabilizarse. Esta variación en la tendencia sugiere que la media no se mantiene constante, lo cual indica que la serie no es estacionaria en media. Además, los residuos presentan picos pronunciados, lo que evidencia la presencia de valores atípicos y posibles cambios en la varianza a lo largo del tiempo.

## Estacionariedad

Para validar lo anteriormente expuesto, realizaremos la prueba de Dickey-Fuller

```{r,warning=FALSE,message=FALSE,echo=FALSE}
library(tseries)
adf.test(serie_log)  

```
 
En este sentido se valida el hecho de que la serie no es estacionaria, es decir, no presenta media, varianza y covarianza constante.

## Resultados de la Descomposicion y Estacionariedad

A partir de lo observado, se concluye que es necesaria una transformación para estabilizar tanto la media como la varianza de la serie temporal [@hyndman2021forecasting]. Por ello, se aplicará una transformación logarítmica con el fin de reducir la variabilidad, seguida de una diferenciación para eliminar la tendencia y lograr una media más constante en el tiempo.

**Primera Diferenciación**

```{r, echo=FALSE,message=FALSE,warning=FALSE}
library(tseries)
serie_log_diff <- diff(serie_log)
plot(serie_log_diff, main = "Serie Logarítmica Diferenciada")
descomposicion_1<- stl(serie_log_diff,s.window = "periodic")
plot(descomposicion_1)
adf.test(serie_log_diff,alternative = "stationary")
```

En este caso al diferenciar la serie una vez se verifica la estacionariedad.

# Pronosticos

## Metodólogia Holter Winter 

La metodología de Holt-Winters, también conocida como suavizamiento exponencial triple, es una técnica ampliamente utilizada en el análisis de series temporales para realizar pronósticos que presentan patrones de tendencia y estacionalidad. Esta metodología extiende el suavizamiento exponencial simple incorporando componentes adicionales que permiten capturar dinámicamente la evolución de la tendencia y la estacionalidad a lo largo del tiempo. Holt-Winters se presenta en dos variantes principales: aditiva y multiplicativa, dependiendo de la naturaleza del componente estacional. Es particularmente útil en contextos donde los datos muestran fluctuaciones regulares en intervalos específicos (como días, semanas o meses), y permite generar predicciones a corto y mediano plazo con un alto grado de precisión. Su implementación práctica ha demostrado ser eficaz en áreas como la economía, la meteorología, la gestión de inventarios y el consumo de recursos, como agua o energía[@HurtadoGarzon2013].

Teniendo en cuenta la fase de preprocesamiento, se observa que la serie transformada por el logaritmo (es decir no se uso la serie diferenciada que es estacionaria) presenta una estacionalidad visible, así como una tendencia definida, caracterizada por un comportamiento que decrece, se estabiliza y vuelve a decrecer. Esto indica que cumple con los criterios visuales necesarios para aplicar la metodología en cuestión. Además, el patrón estacional parece ser claro y repetitivo, lo cual sugiere la presencia de una estacionalidad aditiva. No obstante, al implementar el modelo, es importante considerar los residuos, ya que se identifican picos que podrían estar asociados a eventos atípicos o posibles errores de medición.

Cabe resaltar que esta metodología no requiere que la serie sea estacionaria. En cambio, se enfoca en identificar una tendencia y una estacionalidad bien definidas, ya que el pronóstico se basa en estos dos componentes junto con la media de la serie.


```{r, echo=FALSE, message=FALSE,warning=FALSE}
library(forecast)

# Parámetros
h <- 10  # tamaño del conjunto de prueba
n <- length(serie_log)

# Dividir manualmente con índices
serie_train <- serie_log[1:(n - h)]
serie_test  <- serie_log[(n - h + 1):n]

# Convertir el conjunto de entrenamiento en ts
serie_train_ts <- ts(serie_train, start = start(serie_log), frequency = 52)

# Ajustar el modelo de Holt-Winters
modelo_hw <- HoltWinters(serie_train_ts)

# Predecir
predicciones <- forecast(modelo_hw, h = h)

# Comparar con test
comparacion <- data.frame(
  Real = as.numeric(serie_test),
  Predicho = as.numeric(predicciones$mean)
)

# Calcular RMSE
rmse <- sqrt(mean((comparacion$Real - comparacion$Predicho)^2))
cat("RMSE:", rmse, "\n")

# Crear serie ts para los valores reales de test con la frecuencia adecuada
start_test <- time(serie_train_ts)[length(serie_train_ts)] + 1 / frequency(serie_train_ts)
serie_test_ts <- ts(serie_test, start = start_test, frequency = 52)

# Gráfico
plot(predicciones, main = "Predicción vs valores reales")
lines(serie_test_ts, col = "red", type = "o")
legend("topleft", legend = c("Predicción", "Real"), col = c("blue", "red"), lty = 1)




```

Se observa que los valores pronosticados se ajustan adecuadamente al comportamiento general de la serie; sin embargo, tienden a sobreestimar los valores reales.




## Analisis de los Residuos

Examinaremos los residuos del modelo para evaluar si este ha logrado capturar adecuadamente la estructura subyacente de la serie temporal.

**QQ-plot**

```{r,echo=FALSE}
residuos<- residuals(modelo_hw)
qqnorm(residuos)
qqline(residuos, col = "red")

```

Se observa 

**Prueba de Shapiro-Wilks**

```{r,echo=FALSE,message=FALSE,warning=FALSE}
# Realizar la prueba de normalidad de Shapiro-Wilk
shapiro_test <- shapiro.test(residuos)
print(shapiro_test)

```

Los residuos no siguen una distribución Normal.


**Autocorrelacion**

```{r,echo=FALSE}
# Graficar la función de autocorrelación de los residuos
acf(residuos, main = "Autocorrelación de los residuos")

```

El gráfico ACF de los residuos muestra que no hay autocorrelaciones significativas en los rezagos. Esto sugiere que los residuos son independientes en el tiempo, y por tanto, que el modelo ha logrado capturar adecuadamente la estructura temporal de la serie.

**Homocedasticidad** varianza constante

```{r,echo=FALSE}
# Convertir a vectores simples
valores_ajustados <- as.numeric(modelo_hw$fitted[,1])
residuos_simples <- as.numeric(residuos)

# Graficar sin etiquetas de fecha
plot(valores_ajustados, residuos_simples,
     main = "Residuos vs Valores ajustados",
     xlab = "Valores ajustados", ylab = "Residuos",
     pch = 20, cex = 0.6)  # Puntos más pequeños
abline(h = 0, col = "red")


```

No se observa algun patron claro que indique que la varianza no sea constante, sin embargo se observa la presencia de valores atipicos.

En este sentido ya que no se cumple la normalidad en los supuestos se debe tener cuidado con las inferencias que se realicen sobre este modelo, sin embargo no afecta la aplicación ni los pronósticos hechos por el modelo.



<!--chapter:end:EDA.Rmd-->

## **Modelo ARIMA**

Los modelos autorregresivos integrados de media móvil (ARIMA, por sus siglas en inglés: AutoRegressive Integrated Moving Average) combinan tres componentes:

* AR (Autorregresivo): la serie se explica por sus propios valores pasados.

* I (Integrado): se aplican diferenciaciones a la serie para hacerla estacionaria.

* MA (Media móvil): se modela el error como una combinación lineal de errores pasados.

Un modelo ARIMA se denota como ARIMA(p, d, q), donde:

* p: número de términos autorregresivos (AR).

* d: número de diferenciaciones necesarias para hacer la serie estacionaria.

* q: número de términos de medias móviles (MA).

Estos modelos permiten describir y pronosticar el comportamiento de una serie de tiempo a partir de sus valores y errores pasados.

## **Metodología Box-Jenkins**

La metodología Box-Jenkins es un enfoque sistemático que permite identificar, estimar y validar modelos ARMA o ARIMA que se ajusten adecuadamente a una serie de tiempo. Esta metodología consta de cuatro etapas principales:

1. **Identificación del modelo**
En esta etapa se analiza si la serie es estacionaria. Si no lo es, se aplican transformaciones (como la diferenciación) para lograr la estacionariedad. A continuación, se identifican los posibles valores de los parámetros del modelo ARIMA(p, d, q), con base en el análisis gráfico y estadístico.

**Actividades comunes:**

* Análisis gráfico: para detectar tendencia, estacionalidad o cambios en la media.

* Prueba de estacionariedad: como la prueba de Dickey-Fuller, que evalúa si la serie tiene raíz unitaria.

* Diferenciación: si la serie no es estacionaria, se aplica una o más veces para lograr la estacionariedad y determinar el parámetro d.

* Revisión de ACF y PACF:

ACF (autocorrelación): ayuda a identificar el orden q (media móvil).

PACF (autocorrelación parcial): permite sugerir el orden p (autorregresivo).

2. **Estimación de parámetros**
Una vez identificado el modelo, se ajusta a los datos para estimar sus parámetros.

**Actividades:**

* Estimar los coeficientes mediante métodos como máxima verosimilitud.

* Evaluar la significancia estadística de los parámetros.

* Comparar modelos alternativos utilizando criterios como:

AIC (Criterio de Información de Akaike)

BIC (Criterio de Información Bayesiano)

RMSE (Raíz del error cuadrático medio)

3. **Verificación del modelo**
Se valida que los residuos del modelo se comporten como ruido blanco, es decir, que no presenten autocorrelación y tengan media cero y varianza constante.

**Actividades:**

* Analizar los residuos en el tiempo.

* Revisar los gráficos de ACF y PACF de los residuos.

* Verificar la normalidad mediante histogramas o pruebas como Shapiro-Wilk.

* Verificar independencia mediante pruebas como Ljung-Box.

Si los supuestos no se cumplen, se debe reconsiderar el modelo y repetir las etapas anteriores.

4. **Pronóstico**
Una vez validado el modelo, se procede a generar pronósticos a corto, mediano o largo plazo.

**Actividades:**

* Generar predicciones con intervalos de confianza.

* Comparar los pronósticos con datos reales (si están disponibles).

* Evaluar la precisión del modelo predictivo.

<!--chapter:end:ARIMA.Rmd-->

`r if (knitr:::is_html_output()) '
# Referencias {-}
'`

<!--chapter:end:06-references.Rmd-->

