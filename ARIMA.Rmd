# Metodología Box-Jenkins y Modelos ARIMA

## Modelo ARIMA

Los modelos autorregresivos integrados de media móvil (ARIMA, por sus siglas en inglés: AutoRegressive Integrated Moving Average) combinan tres componentes:

* AR (Autorregresivo): la serie se explica por sus propios valores pasados.

* I (Integrado): se aplican diferenciaciones a la serie para hacerla estacionaria.

* MA (Media móvil): se modela el error como una combinación lineal de errores pasados.

Un modelo ARIMA se denota como ARIMA(p, d, q), donde:

* p: número de términos autorregresivos (AR).

* d: número de diferenciaciones necesarias para hacer la serie estacionaria.

* q: número de términos de medias móviles (MA).

Estos modelos permiten describir y pronosticar el comportamiento de una serie de tiempo a partir de sus valores y errores pasados.


## Metodología Box-Jenkins
La metodología Box-Jenkins es un enfoque sistemático que permite identificar, estimar y validar modelos ARMA o ARIMA que se ajusten adecuadamente a una serie de tiempo. Esta metodología consta de cuatro etapas principales:

1. **Identificación del modelo**
En esta etapa se analiza si la serie es estacionaria. Si no lo es, se aplican transformaciones (como la diferenciación) para lograr la estacionariedad. A continuación, se identifican los posibles valores de los parámetros del modelo ARIMA(p, d, q), con base en el análisis gráfico y estadístico.

**Actividades comunes:**

* Análisis gráfico: para detectar tendencia, estacionalidad o cambios en la media.

* Prueba de estacionariedad: como la prueba de Dickey-Fuller, que evalúa si la serie tiene raíz unitaria.

* Diferenciación: si la serie no es estacionaria, se aplica una o más veces para lograr la estacionariedad y determinar el parámetro d.

* Revisión de ACF y PACF:

ACF (autocorrelación): ayuda a identificar el orden q (media móvil).

PACF (autocorrelación parcial): permite sugerir el orden p (autorregresivo).

2. **Estimación de parámetros**
Una vez identificado el modelo, se ajusta a los datos para estimar sus parámetros.

**Actividades:**

* Estimar los coeficientes mediante métodos como máxima verosimilitud.

* Evaluar la significancia estadística de los parámetros.

* Comparar modelos alternativos utilizando criterios como:

AIC (Criterio de Información de Akaike)

BIC (Criterio de Información Bayesiano)

RMSE (Raíz del error cuadrático medio)

3. **Verificación del modelo**
Se valida que los residuos del modelo se comporten como ruido blanco, es decir, que no presenten autocorrelación y tengan media cero y varianza constante.

**Actividades:**

* Analizar los residuos en el tiempo.

* Revisar los gráficos de ACF y PACF de los residuos.

* Verificar la normalidad mediante histogramas o pruebas como Shapiro-Wilk.

* Verificar independencia mediante pruebas como Ljung-Box.

Si los supuestos no se cumplen, se debe reconsiderar el modelo y repetir las etapas anteriores.

4. **Pronóstico**
Una vez validado el modelo, se procede a generar pronósticos a corto, mediano o largo plazo.

**Actividades:**

* Generar predicciones con intervalos de confianza.

* Comparar los pronósticos con datos reales (si están disponibles).

* Evaluar la precisión del modelo predictivo.

Cabe resaltar que actualmente se dispone de la librería forecast en R, la cual incluye la función auto.arima, que permite seleccionar automáticamente los parámetros del modelo ARIMA de forma eficiente. Este procedimiento se basa en criterios estadísticos como AIC o BIC para identificar la combinación óptima de parámetros (p,d,q).

Gracias a esta automatización, se simplifican varios pasos tradicionales del proceso de modelado, como la inspección visual de los gráficos ACF y PACF, la identificación manual del grado de diferenciación d, y la evaluación de múltiples combinaciones de parámetros para encontrar el mejor modelo.

Por tanto, en esta etapa nos enfocaremos únicamente en la validación de los supuestos del modelo sobre los residuos y en la evaluación del desempeño de los pronósticos. 

## Modelado

```{r,echo=FALSE, message=FALSE,warning=FALSE}
library(forecast)

modelo_arima <- auto.arima(serie_train, seasonal = TRUE, stepwise = FALSE, approximation = FALSE)
summary(modelo_arima)

```
El modelo seleccionado automáticamente mediante la función auto.arima fue un ARIMA(0,1,1). Esto indica que la serie requirió una diferenciación (d=1) para alcanzar la estacionariedad. Además, el modelo no incluye términos autoregresivos (p=0) y cuenta únicamente con un componente de media móvil (q=1), lo cual sugiere que la dinámica de la serie puede ser capturada eficazmente mediante un modelo de tipo MA(1) aplicado a los datos diferenciados.


## Validacion de Supuestos sobre los Residuos

```{r,echo=FALSE,message=FALSE,warning=FALSE}

library(FinTS)
ArchTest(residuals(modelo_arima))
checkresiduals(modelo_arima)
residuosarima<- residuals(modelo_arima)
mean(residuosarima)
shapiro.test(residuosarima)
```

Se observa que los residuos del modelo presentan una media cercana a cero, lo cual es deseable. Además, cumplen con el supuesto de independencia, confirmado mediante la prueba de Ljung-Box (p = 0.3612), y presentan varianza constante, según los resultados de la prueba ARCH LM. No obstante, los residuos no siguen una distribución normal, como lo indica la prueba de normalidad de Shapiro-Wilk. Esta falta de normalidad no invalida el modelo para propósitos de pronóstico, pero sí requiere precaución al realizar inferencias estadísticas, especialmente aquellas que dependen fuertemente del supuesto de normalidad.

## Pronosticos 

```{r,echo=FALSE,warning=FALSE,message=FALSE}
pronostico <- forecast(modelo_arima, h = h)
pronosticos<- as.data.frame(pronostico)
head(pronosticos,5)
serie_test <- ts(serie_test, start = c(2022, 43), frequency = 52)  # Ajusta la fecha inicial según tu caso

```

## Gráfico de Pronosticos 

```{r,echo=FALSE,message=FALSE,warning=FALSE}
library(forecast)

# Parámetros
h <- 10  # tamaño del conjunto de prueba
n <- length(serie_log)

# Dividir en entrenamiento y prueba
serie_train <- serie_log[1:(n - h)]
serie_test  <- serie_log[(n - h + 1):n]

# Convertir entrenamiento en ts
serie_train_ts <- ts(serie_train, start = start(serie_log), frequency = 52)

# Ajustar modelo auto.arima
modelo_arima <- auto.arima(serie_train_ts, seasonal = TRUE, stepwise = FALSE, approximation = FALSE)

# Pronóstico
predicciones <- forecast(modelo_arima, h = h)

# Comparar con valores reales
comparacion <- data.frame(
  Real = as.numeric(serie_test),
  Predicho = as.numeric(predicciones$mean)
)

# Calcular RMSE
rmse <- sqrt(mean((comparacion$Real - comparacion$Predicho)^2))
cat("RMSE:", rmse, "\n")

# Crear serie ts para valores reales del test
start_test <- time(serie_train_ts)[length(serie_train_ts)] + 1 / frequency(serie_train_ts)
serie_test_ts <- ts(serie_test, start = start_test, frequency = 52)

# Gráfico
plot(predicciones, main = "Predicción ARIMA vs valores reales", ylab = "Log Consumo")
lines(serie_test_ts, col = "red", type = "o")
legend("topleft", legend = c("Predicción", "Real"), col = c("blue", "red"), lty = 1)

```

